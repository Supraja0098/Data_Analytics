{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IwnAXfQSxXH",
        "outputId": "d50e8f8f-60f4-4ae1-c4a7-50727aba3f81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.4.1)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=754a3c6bd70b3e265fa8c314ef03f6f5d06bce85bba920cc7c380f654455a4fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.profiledir import ProfileDirError\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from urllib.request import Request, urlopen\n",
        "\n",
        "\n",
        "def get_all_urls(url):\n",
        "  urls=[]\n",
        "  session = requests.Session()\n",
        "  #https://scai.engineering.asu.edu/computer-science-and-engineering-faculty/\n",
        "  response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  links = soup.find_all('div', class_='post-content')\n",
        "  for link in links:\n",
        "    strong = link.find('strong')\n",
        "    url=link.find('a').get('href')\n",
        "    urls.append(url)\n",
        "  return urls\n",
        "\n",
        "def write_to_file(file_name, data, data_type):\n",
        "    with open(file_name, 'w', encoding='utf-8') as file:\n",
        "          if data_type == 'profile_url':\n",
        "            for x in data:\n",
        "              file.write(f\"Faculty URL: {x['url']}\\n\")\n",
        "          elif data_type == 'bio':\n",
        "            for x in data:\n",
        "              file.write(f\"Faculty Bio: {x['bio']}\\n\")\n",
        "          elif data_type == 'courses_taught':\n",
        "            for x in data:\n",
        "              file.write(f\"Courses Taught: {x.get('teaching', 'N/A')}\\n\")\n",
        "          file.write('\\n')\n",
        "\n",
        "\n",
        "\n",
        "def extract_prof_data(urls):\n",
        "  prof_data=[]\n",
        "  for url in urls:\n",
        "    prof ={\n",
        "        'url':\"\",\n",
        "        'name':\"\",\n",
        "        'bio':\"\",\n",
        "        'teaching':[]\n",
        "    }\n",
        "\n",
        "    session = requests.Session()\n",
        "    response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    name = soup.find('h1').text\n",
        "    biography_div= soup.find('div',class_='user__field-profile-biography mb-3')\n",
        "    if biography_div:\n",
        "      # If the div exists, find the <p> tag and extract its text\n",
        "      biography_p = biography_div.find('p')\n",
        "      if biography_p:\n",
        "          bio = biography_p.text\n",
        "      else:\n",
        "          bio = \"NA\"\n",
        "    else:\n",
        "      # If the div doesn't exist, set the 'bio' variable to \"NA\"\n",
        "      bio = \"NA\"\n",
        "    tables = soup.find_all('table',class_='webdir-profile-courses responsive-enabled table')\n",
        "    if not tables:\n",
        "    # If no tables were found, set 'subject_codes' and 'subject_names' to \"NA\" or take any other appropriate action\n",
        "      subject_codes = \"NA\"\n",
        "      subject_names = \"NA\"\n",
        "    else:\n",
        "        subject_codes = []\n",
        "        subject_names = []\n",
        "        for table in tables:\n",
        "            tbody = table.find_all('tbody')\n",
        "            for x in tbody:\n",
        "                subject_codes.append(x.find('td').text)\n",
        "                subject_names.append(x.find_all('td')[1].text)\n",
        "    # for table in tables:\n",
        "    #   tbody = table.find_all('tbody')\n",
        "    #   for x in tbody:\n",
        "    #     subject_codes.append(x.find('td').text)\n",
        "    #     subject_names.append(x.find_all('td')[1].text)\n",
        "    prof['url']=url\n",
        "    prof['bio']=bio\n",
        "    prof['name']=name\n",
        "    prof['teaching']=subject_codes\n",
        "    prof_data.append(prof)\n",
        "  return prof_data\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = 'https://scai.engineering.asu.edu/computer-science-and-engineering-faculty/'\n",
        "    urls = get_all_urls(url)\n",
        "    print(urls)\n",
        "    data = extract_prof_data(urls)\n",
        "    print(data)\n",
        "\n",
        "    # Save faculty profile URLs in a separate file\n",
        "    write_to_file('profile_urls.txt', data, data_type='profile_url')\n",
        "\n",
        "    # Save faculty bios in a separate file\n",
        "    write_to_file('bios.txt', data, data_type='bio')\n",
        "\n",
        "    # Save courses taught in a separate file\n",
        "    write_to_file('courses_taught.txt', data, data_type='courses_taught')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqLSBdsaV-hv",
        "outputId": "8114ba74-e1bd-4940-b51d-479406974204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://isearch.asu.edu/profile/1258895', 'https://isearch.asu.edu/profile/506050', 'https://isearch.asu.edu/profile/1097689', 'https://isearch.asu.edu/profile/3322259', 'https://isearch.asu.edu/profile/231973', 'https://isearch.asu.edu/profile/42976', 'https://isearch.asu.edu/profile/15427', 'https://isearch.asu.edu/profile/2736878', 'https://isearch.asu.edu/profile/3410924/', 'https://isearch.asu.edu/profile/17493', 'https://isearch.asu.edu/profile/2071635', 'https://isearch.asu.edu/profile/3335256', 'https://isearch.asu.edu/profile/1097397', 'https://isearch.asu.edu/profile/20861', 'https://search.asu.edu/profile/4082902', 'https://isearch.asu.edu/profile/328180', 'https://isearch.asu.edu/profile/384970', 'https://isearch.asu.edu/profile/25234', 'https://isearch.asu.edu/profile/3584805', 'https://isearch.asu.edu/profile/75201', 'https://isearch.asu.edu/profile/515694', 'https://isearch.asu.edu/profile/1554300', 'https://isearch.asu.edu/profile/2412296', 'https://isearch.asu.edu/profile/1283831', 'https://isearch.asu.edu/profile/3182641', 'https://isearch.asu.edu/profile/3516139', 'https://isearch.asu.edu/profile/475315', 'https://isearch.asu.edu/profile/313263', 'https://isearch.asu.edu/profile/28616', 'https://isearch.asu.edu/profile/3982178', 'https://isearch.asu.edu/profile/3720292', 'https://isearch.asu.edu/profile/95646', 'https://isearch.asu.edu/profile/472846', 'https://isearch.asu.edu/profile/325953', 'https://isearch.asu.edu/profile/3505050', 'https://isearch.asu.edu/profile/841979', 'https://isearch.asu.edu/profile/3957975', 'https://isearch.asu.edu/profile/60335', 'https://isearch.asu.edu/profile/747601', 'https://isearch.asu.edu/profile/255975', 'https://isearch.asu.edu/profile/1783228', 'https://isearch.asu.edu/profile/10287', 'https://isearch.asu.edu/profile/2203687', 'https://isearch.asu.edu/profile/3298186', 'https://isearch.asu.edu/profile/854979', 'https://isearch.asu.edu/profile/2224799', 'https://isearch.asu.edu/profile/262996', 'https://isearch.asu.edu/profile/72612', 'https://isearch.asu.edu/profile/88253', 'https://isearch.asu.edu/profile/77201', 'https://isearch.asu.edu/profile/2436287', 'https://isearch.asu.edu/profile/198256', 'https://isearch.asu.edu/profile/333046', 'https://isearch.asu.edu/profile/2412294', 'https://search.asu.edu/profile/4383315', 'https://isearch.asu.edu/profile/2076616', 'https://isearch.asu.edu/profile/40210', 'https://isearch.asu.edu/profile/2424157', 'https://isearch.asu.edu/profile/3153940', 'https://isearch.asu.edu/profile/969623', 'https://isearch.asu.edu/profile/3169276', 'https://isearch.asu.edu/profile/2636984', 'https://isearch.asu.edu/profile/518662', 'https://isearch.asu.edu/profile/71640', 'https://isearch.asu.edu/profile/3720292', 'https://isearch.asu.edu/profile/258423', 'https://isearch.asu.edu/profile/52626', 'https://isearch.asu.edu/profile/96096', 'https://isearch.asu.edu/profile/1203192', 'https://isearch.asu.edu/profile/761142', 'https://isearch.asu.edu/profile/3322258', 'https://isearch.asu.edu/profile/1638618', 'https://isearch.asu.edu/profile/109042', 'https://isearch.asu.edu/profile/3810991', 'https://isearch.asu.edu/profile/378651', 'https://isearch.asu.edu/profile/3020558', 'https://isearch.asu.edu/profile/3520440', 'https://isearch.asu.edu/profile/94570', 'https://isearch.asu.edu/profile/2206334', 'https://isearch.asu.edu/profile/2740006', 'https://isearch.asu.edu/profile/3502000']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1j9TFyU-qfS1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}